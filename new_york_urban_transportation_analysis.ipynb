{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfe71e57-ec6b-4539-a252-2331c3015505",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install typing_extensions==3.7.4.3\n",
    "%pip install torch==2.0.0\n",
    "%pip install torch-geometric\n",
    "!pip install folium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import glob\n",
    "from pyspark.sql.functions import col, dayofmonth, to_timestamp, date_format, explode, sequence, expr, coalesce, when, to_date, lit, substring, concat, hour, avg\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, DoubleType, TimestampType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark import StorageLevel\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster, HeatMap\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41abf71d-1b27-4e06-91cb-d8c8d50daa80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Se crea una sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"UberDataProcessing\").getOrCreate()\n",
    "\n",
    "# Se definen las rutas de los archivos (en este script los datos de tiempo y eventos se importaron de unos fihceros previamnete descargados)\n",
    "taxi_zones_path = \"/FileStore/tables/taxi_zones_with_coordinates.csv\"\n",
    "taxi_zones_lookup_path = \"/FileStore/tables/taxi_zone_lookup.csv\"\n",
    "weather_df_path = \"/FileStore/tables/weather_nyc_2024.csv\"\n",
    "events_data_path = \"/FileStore/tables/events.csv\"\n",
    "\n",
    "# Carga de los archivos CSV infiriendo el esquema\n",
    "taxi_zones_df = spark.read.csv(taxi_zones_path, header=True, inferSchema=True)\n",
    "taxi_zones_lookup_df = spark.read.csv(taxi_zones_lookup_path, header=True, inferSchema=True)\n",
    "weather_df = spark.read.csv(weather_df_path, header=True, inferSchema=True)\n",
    "events_df = spark.read.option(\"sep\", \";\").csv(events_data_path, header=True, inferSchema=True)\n",
    "\n",
    "# Lista de archivos a cargar\n",
    "file_paths = [\n",
    "    \"dbfs:/FileStore/tables/fhvhv_tripdata_2024_01.parquet\",\n",
    "    \"dbfs:/FileStore/tables/fhvhv_tripdata_2024_02.parquet\",\n",
    "    \"dbfs:/FileStore/tables/fhvhv_tripdata_2024_03.parquet\",\n",
    "    \"dbfs:/FileStore/tables/fhvhv_tripdata_2024_04.parquet\",\n",
    "    \"dbfs:/FileStore/tables/fhvhv_tripdata_2024_05.parquet\",\n",
    "    \"dbfs:/FileStore/tables/fhvhv_tripdata_2024_06.parquet\",\n",
    "]\n",
    "\n",
    "# Se cargan los archivos Parquet\n",
    "df_list = []\n",
    "for file_path in file_paths:\n",
    "    temp_df = spark.read.parquet(file_path)\n",
    "    df_list.append(temp_df)\n",
    "\n",
    "# Se concatenan todos los DataFrames de la lista\n",
    "uber_df = df_list[0]\n",
    "for df in df_list[1:]:\n",
    "    uber_df = uber_df.union(df)\n",
    "\n",
    "uber_df = uber_df.filter((dayofmonth(col(\"request_datetime\")) >= 1) & (dayofmonth(col(\"request_datetime\")) <= 31))\n",
    "\n",
    "# Mostrar los esquemas que se han inferido\n",
    "taxi_zones_df.printSchema()\n",
    "taxi_zones_lookup_df.printSchema()\n",
    "uber_df.printSchema()\n",
    "\n",
    "# Imprimo en pantalla la cantidad de filas en el DataFrame concatenado\n",
    "print(f\"Cantidad de filas en el DataFrame concatenado: {uber_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f78f1aa3-50ab-46e1-bf92-4265a7b3b5da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Se elige una muestra manejable \n",
    "uber_df = uber_df.sample(fraction=0.025, seed=42)\n",
    "# Imprimo en pantalla la cantidad de filas en el DataFrame concatenado\n",
    "print(f\"Cantidad de filas en el DataFrame concatenado: {uber_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bf25888-0720-450a-9d30-c625f50ce1c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Verifico  cuántas veces aparece 'date' en las columnas\n",
    "date_columns = [c for c in uber_df.columns if 'date' in c.lower()]  # Identificamos columnas con 'date' en su nombre\n",
    "print(f\"Columnas que contienen 'date': {date_columns}\")\n",
    "\n",
    "\n",
    "# Elimino columnas duplicadas\n",
    "for i, col in enumerate(date_columns):\n",
    "    new_name = f\"{col}_{i+1}\" if date_columns.count(col) > 1 else col\n",
    "    uber_df = uber_df.withColumnRenamed(col, new_name)\n",
    "\n",
    "# Identifico columnas numéricas y no numéricas\n",
    "numeric_cols = [\n",
    "    c for c in uber_df.columns \n",
    "    if uber_df.select(c).schema.fields[0].dataType.typeName() in ['integer', 'float', 'double']\n",
    "]\n",
    "print(f\"Columnas numéricas: {numeric_cols}\")\n",
    "\n",
    "# Identifico las columnas no numéricas\n",
    "non_numeric_cols = [c for c in uber_df.columns if c not in numeric_cols]\n",
    "print(f\"Columnas no numéricas: {non_numeric_cols}\")\n",
    "\n",
    "# Calculo valores faltantes\n",
    "\n",
    "missing_values = uber_df.select([\n",
    "    (F.when(uber_df[c].isNull(), 1).otherwise(0)).alias(c) for c in uber_df.columns\n",
    "])\n",
    "\n",
    "# Uso la función 'sum' de PySpark para calcular los valores faltantes por columna\n",
    "missing_values_summary = missing_values.agg(*[\n",
    "    F.sum(missing_values[c]).alias(c) for c in uber_df.columns\n",
    "]).collect()\n",
    "\n",
    "# Imprimo en pantalla el resumen de valores faltantes\n",
    "print(f\"Resumen de valores faltantes: {missing_values_summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a83ea833-c742-481e-9741-7ca4bfaa4130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(missing_values_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1683efa-b394-409c-bbc2-0da0a0a5f6fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creo lel filtro de las zonas de Manhattan en el df de las zonas de Taxi\n",
    "manhattan_location_ids = taxi_zones_df.filter(col(\"borough\") == \"Manhattan\") \\\n",
    "                                       .select(\"LocationID\") \\\n",
    "                                       .rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Filtro los datos de hide-railing para las rutas que son completamente dentro de Manhattan\n",
    "uber_df = uber_df.filter(\n",
    "    (col(\"PULocationID\").isin(manhattan_location_ids) & col(\"DOLocationID\").isin(manhattan_location_ids))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fde081f-b025-4101-ac29-dab2a7b7516c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Cantidad de filas en el DataFrame concatenado: {uber_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b45a70cd-24ca-4ea9-b93d-08c120c5a215",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uber_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2011cb80-7a5a-4a00-bf37-864598d45c5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "events_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dc7cc4c-879c-460c-994e-518d2286a41b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuro la política  de fechas\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "# Elimino duplicados\n",
    "events_df = events_df.dropDuplicates()\n",
    "\n",
    "# Uniformizo las columnas de fecha a tipo Timestamp, manejando ambos formatos de fecha\n",
    "events_df = events_df.withColumn(\n",
    "    \"Start Date/Time\",\n",
    "    coalesce(\n",
    "        to_timestamp(col(\"Start Date/Time\"), \"dd/MM/yyyy HH:mm\"),\n",
    "        to_timestamp(col(\"Start Date/Time\"), \"MM/dd/yyyy hh:mm:ss a\")\n",
    "    )\n",
    ").withColumn(\n",
    "    \"End Date/Time\",\n",
    "    coalesce(\n",
    "        to_timestamp(col(\"End Date/Time\"), \"dd/MM/yyyy HH:mm\"),\n",
    "        to_timestamp(col(\"End Date/Time\"), \"MM/dd/yyyy hh:mm:ss a\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Filtro las filas donde End Date/Time es anterior a Start Date/Time\n",
    "events_df = events_df.filter(col(\"End Date/Time\") >= col(\"Start Date/Time\"))\n",
    "\n",
    "# Creo la secuencia de horas entre Start Date/Time y End Date/Time usando INTERVAL 1 HOUR\n",
    "events_with_hours_df = events_df.withColumn(\n",
    "    \"hour_sequence\",\n",
    "    explode(sequence(\n",
    "        col(\"Start Date/Time\"),\n",
    "        col(\"End Date/Time\"),\n",
    "        expr(\"INTERVAL 1 HOUR\")\n",
    "    ))\n",
    ")\n",
    "\n",
    "# Extraigo la fecha y la hora de la secuencia generada\n",
    "events_with_hours_df = events_with_hours_df.withColumn(\"Date\", date_format(col(\"hour_sequence\"), \"yyyy-MM-dd\")) \\\n",
    "                                           .withColumn(\"Hour\", date_format(col(\"hour_sequence\"), \"HH:00\"))\n",
    "\n",
    "# Creo una columna que marque si un evento ocurre en esa hora\n",
    "events_with_hours_df = events_with_hours_df.withColumn(\n",
    "    \"Event Count\", \n",
    "    when(col(\"Event Type\").isNotNull(), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Agrupo por fecha, hora y tipo de evento, luego pivoto para contar los eventos por tipo de evento\n",
    "aggregated_events_df = events_with_hours_df.groupBy(\"Date\", \"Hour\").pivot(\"Event Type\").agg({\"Event Count\": \"sum\"})\n",
    "\n",
    "# Relleno valores nulos con 0\n",
    "aggregated_events_df = aggregated_events_df.fillna(0)\n",
    "# Se suman todas las columnas que no son ni 'Date' ni 'Hour' para obtener la columna 'nº events'\n",
    "aggregated_events_df = aggregated_events_df.withColumn(\n",
    "    \"nº events\",\n",
    "    sum([F.col(col).cast(\"int\") for col in aggregated_events_df.columns if col not in [\"Date\", \"Hour\"]])\n",
    ")\n",
    "# Imprimo en pantalla el resultado\n",
    "aggregated_events_df.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be3b05f8-32bb-4773-b6e3-920daa8ba273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(events_with_hours_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "057152e2-97bc-451f-85eb-eea5fad3cd75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(aggregated_events_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e05d3ed-b18c-47fd-a140-f844ce0876b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "display(uber_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c96a3419-9de8-452a-a473-532ab39519b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJTe5GBnoZ88",
    "outputId": "65824ced-90d8-4fa0-9675-44a2fb767d49"
   },
   "outputs": [],
   "source": [
    "# Selecciono las columnas requeridas de taxi_zones_df\n",
    "taxi_zones_df_filtered = taxi_zones_df.select(\"LocationID\", \"borough\", \"lat\", \"lon\")\n",
    "\n",
    "# Uno uber_df con taxi_zones_df_filtered en la columna \"PULocationID\" (id de recogida)\n",
    "uber_df = uber_df.join(\n",
    "    taxi_zones_df_filtered,\n",
    "    uber_df[\"PULocationID\"] == taxi_zones_df_filtered[\"LocationID\"],\n",
    "    how=\"left\"\n",
    ").drop(\"LocationID\")  # Elimino el LocationID duplicado tras la unión\n",
    "\n",
    "# Renombro las columnas lat y lon como \"pickup_lat\" y \"pickup_lon\" para evitar futuros duplicados con las coodenadas de recogida \n",
    "uber_df = uber_df.withColumnRenamed(\"lat\", \"pickup_lat\").withColumnRenamed(\"lon\", \"pickup_lon\")\n",
    "\n",
    "# Se imprime en pantalla el resultado final\n",
    "uber_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4758c86-5599-438a-9bd7-024da7a959f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6c4p44HpFxK",
    "outputId": "b7a4b92c-3716-41c1-db30-498e8fa0bda6"
   },
   "outputs": [],
   "source": [
    "taxi_zones_df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "498f48bf-1499-4ba9-a7d5-04d3a7eb7393",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSHHZu7NqXDK",
    "outputId": "c0f86c9e-4a90-4d1f-eabe-451ecd98a834"
   },
   "outputs": [],
   "source": [
    "taxi_zones_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d032ce6b-d7c1-4d3d-9de8-0fbb40f7d741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Q9yc-kZps2f",
    "outputId": "4905735c-e0ea-4306-b777-27f028ceb954"
   },
   "outputs": [],
   "source": [
    "# Renombro las columnas en taxi_zones_df_filtered antes de la unión (en este caso hago lo propio antes para traerme las coordenadas de destino)\n",
    "taxi_zones_df_filtered = taxi_zones_df.select(\"LocationID\", \"lat\", \"lon\") \\\n",
    "    .withColumnRenamed(\"lat\", \"dropoff_lat\") \\\n",
    "    .withColumnRenamed(\"lon\", \"dropoff_lon\")\n",
    "\n",
    "# Asigno alias a los DataFrames antes de la unión (tuve problemas para unirlos con los mismos nombres)\n",
    "uber_df_alias = uber_df.alias(\"uber\")\n",
    "taxi_zones_df_filtered_alias = taxi_zones_df_filtered.alias(\"taxi_zones\")\n",
    "\n",
    "# Realizo la unión usando los alias y eliminando columnas redundantes\n",
    "uber_df = uber_df_alias.join(\n",
    "    taxi_zones_df_filtered_alias,\n",
    "    uber_df_alias[\"DOLocationID\"] == taxi_zones_df_filtered_alias[\"LocationID\"],\n",
    "    how=\"left\"\n",
    ").drop(taxi_zones_df_filtered_alias[\"LocationID\"])  # Elimino de nuevo el LocationID redundante\n",
    "\n",
    "# Imprimo en pantalla el resultado final\n",
    "uber_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78fe9028-c2f6-4c58-bea9-a42c706a965a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6gxfo_jpsF-l",
    "outputId": "1f9d1dab-78ea-4a84-a2a8-8bba75b3b40a"
   },
   "outputs": [],
   "source": [
    "uber_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "155b2c50-d420-4b83-aa57-e547c9e23f46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPArbVpstTbC",
    "outputId": "b2364d27-af4f-4856-af9f-1c67a5452616"
   },
   "outputs": [],
   "source": [
    "# Limpio el DataFrame de hide-railing y se calculan también las columnas requeridas\n",
    "uber_cleaned = uber_df.select(\n",
    "    # Coordenadas de salida (latitud y longitud)\n",
    "    F.col(\"pickup_lat\").alias(\"pickup_latitude\"),\n",
    "    F.col(\"pickup_lon\").alias(\"pickup_longitude\"),\n",
    "    # ID de localización\n",
    "    F.col(\"PULocationID\").alias(\"pickup_location_id\"),\n",
    "    F.col(\"DOLocationID\").alias(\"dropoff_location_id\"),\n",
    "\n",
    "    # Coordenadas de llegada (latitud y longitud)\n",
    "    F.col(\"dropoff_lat\").alias(\"dropoff_latitude\"),\n",
    "    F.col(\"dropoff_lon\").alias(\"dropoff_longitude\"),\n",
    "\n",
    "    # Fecha y hora de la solicitud\n",
    "    F.col(\"request_datetime\").alias(\"request_datetime\"),\n",
    "\n",
    "    # Precio total sumando las tarifas y tasas, utilizando coalesce para manejar posibles NULLs\n",
    "    (\n",
    "        F.coalesce(F.col(\"base_passenger_fare\"), F.lit(0)) +\n",
    "        F.coalesce(F.col(\"tolls\"), F.lit(0)) +\n",
    "        F.coalesce(F.col(\"bcf\"), F.lit(0)) +\n",
    "        F.coalesce(F.col(\"sales_tax\"), F.lit(0)) +\n",
    "        F.coalesce(F.col(\"congestion_surcharge\"), F.lit(0)) +\n",
    "        F.coalesce(F.col(\"airport_fee\"), F.lit(0))\n",
    "    ).alias(\"total_price\"),\n",
    "\n",
    "    # Retraso en minutos (calculado como la diferencia entre pickup_datetime y request_datetime)\n",
    "    ((F.unix_timestamp(F.col(\"pickup_datetime\")) - F.unix_timestamp(F.col(\"request_datetime\"))) / 60).alias(\"delay_minutes\"),\n",
    "\n",
    "    # Tiempo total del viaje en minutos (calculado como la diferencia entre dropoff_datetime y request_datetime)\n",
    "    ((F.unix_timestamp(F.col(\"dropoff_datetime\")) - F.unix_timestamp(F.col(\"pickup_datetime\"))) / 60).alias(\"total_trip_time_minutes\"),\n",
    "\n",
    "    # Licencia\n",
    "    F.col(\"hvfhs_license_num\").alias(\"license\"),\n",
    "\n",
    "    # Conversión de millas a kilómetros (en el trabajo hablo siempre de kilómetros)\n",
    "    (F.col(\"trip_miles\") * 1.60934).alias(\"trip_kilometers\"),\n",
    "    # Hora del día extraída de request_datetime\n",
    "    F.hour(F.col(\"request_datetime\")).alias(\"hour_of_day\"),\n",
    "\n",
    "    # Día de la semana extraído de request_datetime (1 = Domingo, 7 = Sábado)\n",
    "    F.dayofweek(F.col(\"request_datetime\")).alias(\"day_of_week\"),\n",
    "    F.to_date(F.col(\"request_datetime\")).alias(\"date\")\n",
    ")\n",
    "#Elimino valores faltantes de dropoff longitud ya que hay dos id de zonas que no se disponen, por lo que se ha  decidido eliminar\n",
    "uber_cleaned = uber_cleaned.dropna(subset=[\"dropoff_longitude\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63e46fd5-8d20-480a-ad7a-30fc3fb5b9fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  Imprimo la cantidad de filas del df para comprobar si ha sucedido algo raro\n",
    "print(f\"Cantidad de filas en el DataFrame concatenado: {uber_cleaned.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2569c2fa-1c95-4ad8-b07c-993e701960ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(uber_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "722f6938-a587-4f41-8ab0-79c753efe4ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Rango de fechas\n",
    "fecha_min = \"2024-01-01\"\n",
    "fecha_max = \"2024-07-01\"\n",
    "\n",
    "# Me cercioro de que las fechas estén en formato adecuado\n",
    "uber_cleaned = uber_cleaned.withColumn(\"date\", to_date(col(\"date\"), \"yyyy-MM-dd\"))\n",
    "aggregated_events_df = aggregated_events_df.withColumn(\"Date\", to_date(col(\"Date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Filtro por rango de fechas\n",
    "uber_cleaned = uber_cleaned.filter((col(\"date\") >= lit(fecha_min)) & (col(\"date\") <= lit(fecha_max)))\n",
    "aggregated_events_df = aggregated_events_df.filter((col(\"Date\") >= lit(fecha_min)) & (col(\"Date\") <= lit(fecha_max)))\n",
    "\n",
    "# Aquí ajusto el formato de la hora para que sean equivalentes\n",
    "\n",
    "# Convierto `hour_of_day` (entero) a formato \"14:00\"\n",
    "uber_cleaned = uber_cleaned.withColumn(\"hour_of_day_formatted\", concat(col(\"hour_of_day\").cast(\"string\"), lit(\":00\")))\n",
    "\n",
    "# Convierto `Hour` (en formato \"14:00\") a tipo  entero \"14\"\n",
    "aggregated_events_df = aggregated_events_df.withColumn(\"Hour_int\", substring(col(\"Hour\"), 1, 2).cast(\"int\"))\n",
    "\n",
    "# Renombro columnas con espacios o caracteres especiales\n",
    "aggregated_events_df = aggregated_events_df.withColumnRenamed(\"nº events\", \"num_events\")\n",
    "print(f\"Registros antes del join: {uber_cleaned.count()}\")\n",
    "# Hago un left join entre uber_cleaned y aggregated_events_df\n",
    "uber_cleaned = uber_cleaned.join(\n",
    "    aggregated_events_df,\n",
    "    (uber_cleaned.date == aggregated_events_df.Date) & (uber_cleaned.hour_of_day == aggregated_events_df.Hour_int),\n",
    "    how=\"left\"\n",
    ")\n",
    "print(f\"Registros después del join: {uber_cleaned.count()}\")\n",
    "\n",
    "# Relleno los valores null en la columna 'num_events' con 0\n",
    "uber_cleaned = uber_cleaned.fillna({\"num_events\": 0})\n",
    "\n",
    "# Renombro de vuelta la columna `num_events` a `nº events`\n",
    "uber_cleaned = uber_cleaned.withColumnRenamed(\"num_events\", \"nº events\")\n",
    "\n",
    "# Imprimo el df combinado\n",
    "display(uber_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cf4bf9a-97c0-42df-b296-ef2e0968eeaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Bz4lZH71Emn",
    "outputId": "670a5d2c-3606-49b7-dd94-0be036021e1b"
   },
   "outputs": [],
   "source": [
    "\n",
    "weather_df = weather_df.withColumnRenamed(\"index\", \"time\")\n",
    "\n",
    "# Me aseguro  de que el tipo de dato es timestamp\n",
    "weather_df = weather_df.withColumn(\"time\", F.col(\"time\").cast(\"timestamp\"))\n",
    "weather_df.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f39b05da-2b6e-499a-9828-d100374265a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# esto es para dinamizar la columna coco\n",
    "# Paso a string la columna coco\n",
    "weather_df = weather_df.withColumn(\"coco\", F.col(\"coco\").cast(\"string\"))\n",
    "\n",
    "# Extraigo los valores únicos de la columna 'coco' para crear una columna por cada valor\n",
    "unique_values = weather_df.select(\"coco\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Creo dinámicamente una columna para cada valor único en 'coco'\n",
    "for value in unique_values:\n",
    "    weather_df = weather_df.withColumn(\n",
    "        f\"coco_{value}\",\n",
    "        F.when(F.col(\"coco\") == value, 1).otherwise(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd81b087-235b-4ea7-b253-86e40e2d3f62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdd18504-4cda-4cc5-999c-b98b27bd8775",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "M0RYDZKs1IXw"
   },
   "outputs": [],
   "source": [
    "# Realizo la unión, cruzando los datos por fecha y hora\n",
    "uber_weather_df = uber_cleaned.join(\n",
    "    weather_df,\n",
    "    (uber_cleaned[\"request_datetime\"] >= weather_df[\"time\"]) & (uber_cleaned[\"request_datetime\"] < (weather_df[\"time\"] + F.expr(\"INTERVAL 1 HOUR\"))),\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dd5d0ed-85d1-43e0-913e-293f97ac23b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fBfv9sjx24In",
    "outputId": "341d0850-7b7c-411e-bfa1-c412fc04a968"
   },
   "outputs": [],
   "source": [
    "uber_weather_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2db86e54-18c1-45f5-9254-c5d688b15e0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajBq5M_QJ5G9",
    "outputId": "be2cbec6-e100-4b49-b24a-0b2920e14133"
   },
   "outputs": [],
   "source": [
    "# Obtengo la cantidad de columnas\n",
    "num_columnas = len(uber_weather_df.columns)\n",
    "\n",
    "# Realizo un muestreo para obtener una aproximación del conteo de filas, mejor que .count() en datos grandes\n",
    "num_filas = uber_weather_df.rdd.countApprox(timeout=5000)  # Ajusta el timeout según el tamaño de tu dataset\n",
    "\n",
    "print(f\"El DataFrame tiene aproximadamente {num_filas} filas y {num_columnas} columnas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dae9dd6a-5dfd-487c-959a-f42369c8f76d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "S3bmOrh_M3Zk"
   },
   "outputs": [],
   "source": [
    "# Filtro las  filas donde las tres columnas tienen valores mayores o iguales a 0 (se considera imposible y un error)\n",
    "uber_weather_df = uber_weather_df[\n",
    "    (uber_weather_df['total_price'] >= 0) &\n",
    "    (uber_weather_df['delay_minutes'] >= 0) &\n",
    "    (uber_weather_df['total_trip_time_minutes'] >= 0)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bad6175-99d2-43ac-b50f-31967dff7aa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculo el tiempo total de viaje en horas\n",
    "uber_weather_df = uber_weather_df.withColumn(\n",
    "    'total_trip_time_hours', \n",
    "    uber_weather_df['total_trip_time_minutes'] / 60\n",
    ")\n",
    "\n",
    "# Calculo la velocidad promedio en km/h\n",
    "uber_weather_df = uber_weather_df.withColumn(\n",
    "    'speed_kmh', \n",
    "    uber_weather_df['trip_kilometers'] / uber_weather_df['total_trip_time_hours']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21731946-0233-4864-a743-347b6bff3378",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(uber_weather_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e0a8a1d-5eed-4728-9eb0-39e566270e18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cuento los valores nulos en la columna 'total_price'\n",
    "\n",
    "null_count = uber_weather_df.filter(uber_weather_df.total_price.isNull()).count()\n",
    "print(f\"Cantidad de valores nulos en 'total_price': {null_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b8d56f7-eeaf-4bdb-a302-9c19b2c47cf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsKvINxXKNtN",
    "outputId": "92c699d6-73d0-4916-f068-39d946d6f610"
   },
   "outputs": [],
   "source": [
    "uber_weather_df.cache()\n",
    "# Selecciono de columnas de duración y distancia para descripción valores estadísticos generales \n",
    "uber_weather_df.select(\"total_trip_time_minutes\", \"trip_kilometers\",\"total_price\",\"delay_minutes\", \"speed_kmh\").describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ada7065b-0ca9-4165-acf7-a86eeb2c6db8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKSVKPnuKYer",
    "outputId": "d23a4ad7-fec3-4de6-8c81-799cc45eed1d"
   },
   "outputs": [],
   "source": [
    "uber_weather_df.cache()\n",
    "# Resumen de temperatura y humedad\n",
    "uber_weather_df.select(\"temp\", \"rhum\").describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcfbb4dd-f66c-4deb-b9f5-30c1a36066a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihaEC229KdY-",
    "outputId": "0da64d27-1f4b-4e7f-855c-7d914da6535e"
   },
   "outputs": [],
   "source": [
    "uber_weather_df.cache()\n",
    "# Relación entre precio total y temperatura\n",
    "uber_weather_df.groupBy(\"temp\").avg(\"total_price\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bcc8f08-e761-418d-a1b9-8cb2f8d81b26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_A03wudMKidO",
    "outputId": "06058191-e5a9-41df-f43d-7dd96970b7c8"
   },
   "outputs": [],
   "source": [
    "uber_weather_df.cache()\n",
    "# Ubicaciones de recogida más frecuentes\n",
    "uber_weather_df.groupBy(\"pickup_location_id\").count().orderBy(\"count\", ascending=False).show(10)\n",
    "# Ubicaciones de destino más frecuentes\n",
    "uber_weather_df.groupBy(\"dropoff_location_id\").count().orderBy(\"count\", ascending=False).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "840ae7bd-ce7c-4871-91b0-06c4a3e8f9b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDNFFC5tKpVx",
    "outputId": "660647a3-c982-4245-f435-8f4bca042f30"
   },
   "outputs": [],
   "source": [
    "uber_weather_df.cache()\n",
    "# Promedio de precio total por hora del día\n",
    "uber_weather_df.withColumn(\"hour\", hour(\"request_datetime\")) \\\n",
    "               .groupBy(\"hour\").avg(\"total_price\").orderBy(\"hour\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd4abe0c-758b-4ff9-89c4-a08bbc24fb93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "id": "WE2NYX_AOz6N",
    "outputId": "b87a9b30-d2cd-4c8c-80f3-16b5bfc707bb"
   },
   "outputs": [],
   "source": [
    "# Configuro el estilo de seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Convierto DataFrame de PySpark a pandas\n",
    "uber_weather_pd_df = uber_weather_df.toPandas()\n",
    "\n",
    "# Selecciono las columnas numéricas para análisis de correlación\n",
    "numeric_columns = uber_weather_pd_df.select_dtypes(include=['number']).columns\n",
    "uber_weather_numeric_df = uber_weather_pd_df[numeric_columns]  # DataFrame solo con columnas numéricas\n",
    "\n",
    "# Creo una figura con varios subplots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 18))  # Aumentamos el tamaño para más subplots\n",
    "\n",
    "# 1. Histograma de la distribución de los precios\n",
    "sns.histplot(uber_weather_pd_df['total_price'], bins=30, kde=True, color=\"skyblue\", ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Distribución de los Precios Totales\")\n",
    "axes[0, 0].set_xlabel(\"Precio Total\")\n",
    "axes[0, 0].set_ylabel(\"Frecuencia\")\n",
    "\n",
    "# 2. Dispersión de retrasos vs. tiempo total de viaje\n",
    "sns.scatterplot(data=uber_weather_pd_df, x=\"total_trip_time_minutes\", y=\"delay_minutes\", ax=axes[0, 1], color=\"salmon\")\n",
    "axes[0, 1].set_title(\"Retrasos en función del Tiempo Total del Viaje\")\n",
    "axes[0, 1].set_xlabel(\"Tiempo Total del Viaje (minutos)\")\n",
    "axes[0, 1].set_ylabel(\"Retraso (minutos)\")\n",
    "\n",
    "# 3. Dispersión de precio vs. tiempo total de viaje\n",
    "sns.scatterplot(data=uber_weather_pd_df, x=\"total_trip_time_minutes\", y=\"total_price\", ax=axes[1, 0], color=\"lightgreen\")\n",
    "axes[1, 0].set_title(\"Relación entre Precio y Tiempo Total del Viaje\")\n",
    "axes[1, 0].set_xlabel(\"Tiempo Total del Viaje (minutos)\")\n",
    "axes[1, 0].set_ylabel(\"Precio Total\")\n",
    "\n",
    "# 4. Boxplots para detectar valores extremos\n",
    "sns.boxplot(data=uber_weather_pd_df[['total_price', 'delay_minutes', 'total_trip_time_minutes']], ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Boxplots de Precios, Retrasos y Tiempo Total de Viaje\")\n",
    "axes[1, 1].set_ylabel(\"Valor\")\n",
    "\n",
    "# 5. Subplot de la velocidad promedio por hora\n",
    "\n",
    "# Calculo primero la velocidad promedio por hora\n",
    "speed_by_hour = uber_weather_pd_df.groupby('hour_of_day')['speed_kmh'].mean().reset_index()\n",
    "# Genero como tal el gráfico\n",
    "sns.lineplot(data=speed_by_hour, x='hour_of_day', y='speed_kmh', marker='o', ax=axes[2, 0], color=\"purple\")\n",
    "axes[2, 0].set_title(\"Velocidad Promedio por Hora\")\n",
    "axes[2, 0].set_xlabel(\"Hora del Día\")\n",
    "axes[2, 0].set_ylabel(\"Velocidad Promedio (km/h)\")\n",
    "\n",
    "# 6. Subplot de un mapa de calor de los pares de pickup_location_id y dropoff_location_id\n",
    "# Creo una tabla de frecuencias de los pares de ubicaciones\n",
    "pickup_dropoff_counts = uber_weather_pd_df.groupby(['pickup_location_id', 'dropoff_location_id']).size().reset_index(name='count')\n",
    "\n",
    "# Pivoto la tabla para crear la matriz de correlación\n",
    "heatmap_data = pickup_dropoff_counts.pivot('pickup_location_id', 'dropoff_location_id', 'count').fillna(0)\n",
    "\n",
    "sns.heatmap(heatmap_data, cmap=\"YlGnBu\", ax=axes[2, 1], cbar_kws={'label': 'Frecuencia'}, annot=False)\n",
    "axes[2, 1].set_title(\"Mapa de Calor: Pares Recogida vs Destino más Demandados\")\n",
    "axes[2, 1].set_xlabel(\"ID Destino\")\n",
    "axes[2, 1].set_ylabel(\"ID Recogida\")\n",
    "\n",
    "# Ajusto el layout para evitar solapamientos\n",
    "plt.tight_layout()\n",
    "\n",
    "# Imprimo los gráficos en pantalla\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89c9617a-0a95-4f87-9e21-ee1d622954b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uber_weather_df.cache()\n",
    "# Distribución de la velocidad de circulación\n",
    "uber_weather_df.select(\"speed_kmh\").describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50af6de9-1d9a-486b-aa37-bf4d9f9d47d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Quito los valores atípicos: la lógica se define en el documento\n",
    "# Lo dejo el df en memoria para acelerar operaciones futuras\n",
    "uber_weather_df = uber_weather_df.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "# Calculo los cuartiles e IQR solo para la columna de precio\n",
    "Q1_price, Q3_price = uber_weather_df.approxQuantile(\"total_price\", [0.25, 0.75], 0.05)\n",
    "IQR_price = Q3_price - Q1_price\n",
    "\n",
    "# Filtro valores atípicos y establecer límites lógicos\n",
    "uber_weather_df = uber_weather_df.filter(\n",
    "    (col(\"trip_kilometers\") <= 30) &  # Distancia máxima lógica para Manhattan\n",
    "    (col(\"speed_kmh\") <= 80) &         # Velocidad máxima permitida\n",
    "    (col(\"total_trip_time_minutes\") <= 120) &  # Tiempo total máximo permitido\n",
    "    (col(\"total_price\") >= (Q1_price - 1.5 * IQR_price)) &  # Precio dentro del rango intercuartílico extendido\n",
    "    (col(\"total_price\") <= 200) &    # Máximo precio permitido es 200 USD\n",
    "    (col(\"delay_minutes\") <= 120) &  # Máximo retraso permitido\n",
    "    (col(\"total_trip_time_minutes\") >= 0)  # Tiempo de viaje no negativo\n",
    ")\n",
    "\n",
    "#  Ajusto particiones para mejorar el rendimiento , no es necesario pero mejora el rendimiento\n",
    "uber_weather_df = uber_weather_df.repartition(\"total_price\")\n",
    "\n",
    "# Muestro resultados limitados solo 5 \n",
    "uber_weather_df.show(5, truncate=False)\n",
    "\n",
    "# Libero memoria\n",
    "uber_weather_df.unpersist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f84f3ff4-9103-4503-8a04-27ab88bbbe51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuro el estilo de seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Convierto el df de PySpark a pandas\n",
    "uber_weather_pd_df = uber_weather_df.toPandas()\n",
    "\n",
    "# Selecciono las columnas numéricas para análisis de correlación\n",
    "numeric_columns = uber_weather_pd_df.select_dtypes(include=['number']).columns\n",
    "uber_weather_numeric_df = uber_weather_pd_df[numeric_columns]  # DataFrame solo con columnas numéricas\n",
    "\n",
    "# Creo una figura con múltiples subplots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 18))  # Aumentamos el tamaño para incluir más subplots\n",
    "\n",
    "# 1. Histograma de la distribución de los precios\n",
    "sns.histplot(uber_weather_pd_df['total_price'], bins=30, kde=True, color=\"skyblue\", ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Distribución de los Precios Totales\")\n",
    "axes[0, 0].set_xlabel(\"Precio Total\")\n",
    "axes[0, 0].set_ylabel(\"Frecuencia\")\n",
    "\n",
    "# 2. Dispersión de retrasos vs. tiempo total de viaje\n",
    "sns.scatterplot(data=uber_weather_pd_df, x=\"total_trip_time_minutes\", y=\"delay_minutes\", ax=axes[0, 1], color=\"salmon\")\n",
    "axes[0, 1].set_title(\"Retrasos en función del Tiempo Total del Viaje\")\n",
    "axes[0, 1].set_xlabel(\"Tiempo Total del Viaje (minutos)\")\n",
    "axes[0, 1].set_ylabel(\"Retraso (minutos)\")\n",
    "\n",
    "# 3. Dispersión de precio vs. tiempo total de viaje\n",
    "sns.scatterplot(data=uber_weather_pd_df, x=\"total_trip_time_minutes\", y=\"total_price\", ax=axes[1, 0], color=\"lightgreen\")\n",
    "axes[1, 0].set_title(\"Relación entre Precio y Tiempo Total del Viaje\")\n",
    "axes[1, 0].set_xlabel(\"Tiempo Total del Viaje (minutos)\")\n",
    "axes[1, 0].set_ylabel(\"Precio Total\")\n",
    "\n",
    "# 4. Boxplots para detectar valores extremos\n",
    "sns.boxplot(data=uber_weather_pd_df[['total_price', 'delay_minutes', 'total_trip_time_minutes']], ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Boxplots de Precios, Retrasos y Tiempo Total de Viaje\")\n",
    "axes[1, 1].set_ylabel(\"Valor\")\n",
    "\n",
    "# 5. Subplot de la velocidad promedio por hora\n",
    "\n",
    "# Calculo la velocidad promedio por hora y el conteo (demanda)\n",
    "speed_and_demand_by_hour = uber_weather_pd_df.groupby('hour_of_day').agg({\n",
    "    'speed_kmh': 'mean',\n",
    "    'hour_of_day': 'count'  # Esto cuenta las filas para representar la demanda\n",
    "}).rename(columns={'hour_of_day': 'demand'}).reset_index()\n",
    "\n",
    "sns.lineplot(\n",
    "    data=speed_and_demand_by_hour, \n",
    "    x=\"hour_of_day\", \n",
    "    y=\"demand\", \n",
    "    marker=\"o\", \n",
    "    ax=axes[2, 0], \n",
    "    color=\"blue\", \n",
    "    label=\"Demanda\",\n",
    "    ci=95\n",
    ")\n",
    "\n",
    "# Configuro títulos y etiquetas\n",
    "axes[2, 0].set_title(\"Demanda por Hora de Hide-Railing\")\n",
    "axes[2, 0].set_xlabel(\"Hora del Día\")\n",
    "axes[2, 0].set_ylabel(\"Demanda Total\")\n",
    "axes[2, 0].legend(title=\"Métrica\")\n",
    "\n",
    "\n",
    "# 6. Subplot de un mapa de calor de los pares de pickup_location_id y dropoff_location_id\n",
    "# Creo una tabla de frecuencias de los pares de ubicaciones\n",
    "pickup_dropoff_counts = uber_weather_pd_df.groupby(['pickup_location_id', 'dropoff_location_id']).size().reset_index(name='count')\n",
    "\n",
    "# Pivoto la tabla para crear la matriz de correlación\n",
    "heatmap_data = pickup_dropoff_counts.pivot('pickup_location_id', 'dropoff_location_id', 'count').fillna(0)\n",
    "\n",
    "sns.heatmap(heatmap_data, cmap=\"YlGnBu\", ax=axes[2, 1], cbar_kws={'label': 'Frecuencia'}, annot=False)\n",
    "\n",
    "axes[2, 1].set_title(\"Mapa de Calor: Pares Recogida vs Destino más Demandados\")\n",
    "axes[2, 1].set_xlabel(\"ID Destino\")\n",
    "axes[2, 1].set_ylabel(\"ID Recogida\")\n",
    "\n",
    "# Ajusto el layout para evitar solapamientos\n",
    "plt.tight_layout()\n",
    "\n",
    "# Imprimo los gráficos en pantalla\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_and_demand_by_hour = uber_weather_pd_df.groupby('hour_of_day').agg({\n",
    "    'speed_kmh': 'mean',\n",
    "    'hour_of_day': 'count'  # Esto cuenta las filas para representar la demanda\n",
    "}).rename(columns={'hour_of_day': 'demand'}).reset_index()\n",
    "\n",
    "# Creo el escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizo las columnas \"speed_kmh\" y \"demand\"\n",
    "speed_and_demand_by_hour[[\"speed_kmh\", \"demand\"]] = scaler.fit_transform(\n",
    "    speed_and_demand_by_hour[[\"speed_kmh\", \"demand\"]]\n",
    ")\n",
    "\n",
    "# Creo el gráfico con las métricas normalizadas\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(\n",
    "    data=speed_and_demand_by_hour, \n",
    "    x=\"hour_of_day\", \n",
    "    y=\"speed_kmh\", \n",
    "    marker=\"o\", \n",
    "    ax=axes[2, 0], \n",
    "    color=\"purple\", \n",
    "    label=\"Velocidad Promedio (Normalizada)\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=speed_and_demand_by_hour, \n",
    "    x=\"hour_of_day\", \n",
    "    y=\"demand\", \n",
    "    marker=\"x\", \n",
    "    ax=axes[2, 0], \n",
    "    color=\"orange\", \n",
    "    label=\"Demanda (Normalizada)\"\n",
    ")\n",
    "# Detalles del gráfico\n",
    "plt.title(\"Velocidad Promedio y Demanda por Día de la Semana (Normalizadas)\")\n",
    "plt.xlabel(\"Día de la Semana\")\n",
    "plt.ylabel(\"Valores Normalizados\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestro el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b08f5174-fddc-471b-bee1-9230aa502158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(speed_and_demand_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a85e8061-e896-416e-8a95-fe7d1eede8d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reparticiono el df antes de realizar la operación, esto ayuda a distribuir los datos de manera eficiente\n",
    "uber_weather_df = uber_weather_df.repartition(100) \n",
    "\n",
    "# lo cacheo para optimizar el rendimiento\n",
    "uber_weather_df.cache()\n",
    "\n",
    "# Agrupo de manera específica (por ruta)\n",
    "time_by_location_hour = (\n",
    "    uber_weather_df\n",
    "    .groupBy(\n",
    "        F.col(\"pickup_latitude\").alias(\"pickup_latitude\"),\n",
    "        F.col(\"pickup_longitude\").alias(\"pickup_longitude\"),\n",
    "        F.col(\"dropoff_latitude\").alias(\"dropoff_latitude\"),\n",
    "        F.col(\"dropoff_longitude\").alias(\"dropoff_longitude\"),\n",
    "        F.to_date(\"request_datetime\").alias(\"date\"),\n",
    "        F.hour(\"request_datetime\").alias(\"hour\"),\n",
    "        F.dayofweek(\"request_datetime\").alias(\"day_of_week\")  # Añado el día de la semana\n",
    "    )\n",
    "    .agg(\n",
    "        F.avg(\"total_trip_time_minutes\").alias(\"avg_trip_time_minutes\"),\n",
    "        F.avg(\"temp\").alias(\"avg_temp\"),\n",
    "        F.avg(\"trip_kilometers\").alias(\"avg_distance\"),\n",
    "        F.avg(\"rhum\").alias(\"avg_rhum\"),\n",
    "        F.avg(\"speed_kmh\").alias(\"avg_speed_kmh\"),\n",
    "        F.avg(\"delay_minutes\").alias(\"avg_delay_minutes\"),\n",
    "        F.avg(\"prcp\").alias(\"avg_prcp\"),\n",
    "        F.avg(\"nº events\").alias(\"avg_events\"),\n",
    "        F.count(\"*\").alias(\"demand_count\")\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c586551-2da8-45af-bbfe-3fe931aedf17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(time_by_location_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb123ca4-23a5-4f68-bfdb-e38a931edfd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Agrupo de forma mas general para identificar mejor las correlaciones\n",
    "time_by_location_hour_day = (\n",
    "    uber_weather_df\n",
    "    .groupBy(\n",
    "        F.hour(\"request_datetime\").alias(\"hour\"),\n",
    "        F.dayofweek(\"request_datetime\").alias(\"day_of_week\")  # Añado el día de la semana\n",
    "    )\n",
    "    .agg(\n",
    "        F.avg(\"total_trip_time_minutes\").alias(\"avg_trip_time_minutes\"),\n",
    "        F.avg(\"temp\").alias(\"avg_temp\"),\n",
    "        F.avg(\"trip_kilometers\").alias(\"avg_distance\"),\n",
    "        F.avg(\"rhum\").alias(\"avg_rhum\"),\n",
    "        F.avg(\"wspd\").alias(\"avg_wspd\"),\n",
    "        F.avg(\"speed_kmh\").alias(\"avg_speed_kmh\"),\n",
    "        F.avg(\"delay_minutes\").alias(\"avg_delay_minutes\"),\n",
    "        F.avg(\"prcp\").alias(\"avg_prcp\"),\n",
    "        F.avg(\"nº events\").alias(\"avg_events\"),\n",
    "        F.count(\"*\").alias(\"demand_count\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa959e1b-e01e-4b91-8085-40ceb4450d80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "time_by_location_hour_day = time_by_location_hour_day.cache()\n",
    "\n",
    "# Lo paso a pandas\n",
    "\n",
    "time_by_location_hour_day_pd = time_by_location_hour_day.toPandas()\n",
    "\n",
    "# Creo la matriz de correlación en Pandas para visualizarla con seaborn/matplotlib\n",
    "\n",
    "correlation_matrix = time_by_location_hour_day_pd[[\"avg_trip_time_minutes\", \"avg_temp\", \"avg_rhum\", \"avg_speed_kmh\", \"avg_prcp\", \"avg_events\", \"avg_wspd\", \"demand_count\",\"avg_distance\", \"avg_delay_minutes\"]].corr()\n",
    "\n",
    "# Configuro el tamaño del gráfico\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Dibujo el mapa de calor\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, square=True, fmt=\".2f\",\n",
    "            cbar_kws={\"shrink\": .8}, annot_kws={\"size\": 10})\n",
    "\n",
    "# Configuración adicional del mapa de calor\n",
    "plt.title(\"Matriz de Correlación General\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Imprimo en pantalla el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81bfa683-43b1-4691-8e1f-a7dd89f4c273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "time_by_location_hour = time_by_location_hour.cache()\n",
    "\n",
    "# Lo paso a pandas\n",
    "\n",
    "time_by_location_hour_pd = time_by_location_hour.toPandas()\n",
    "\n",
    "# Creo la matriz de correlación en Pandas para visualizarla con seaborn/matplotlib\n",
    "\n",
    "correlation_matrix = time_by_location_hour_pd[[\"avg_trip_time_minutes\", \"avg_temp\", \"avg_rhum\", \"avg_speed_kmh\", \"avg_prcp\", \"avg_events\", \"demand_count\",\"avg_distance\", \"avg_delay_minutes\"]].corr()\n",
    "\n",
    "# Configuro el tamaño del gráfico\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Creo el mapa de calor\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, square=True, fmt=\".2f\",\n",
    "            cbar_kws={\"shrink\": .8}, annot_kws={\"size\": 10})\n",
    "\n",
    "# Configuración adicional del del mapa de calor\n",
    "plt.title(\"Matriz de Correlación General a nivel de ruta\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5ad4373-1424-4058-9cf1-27c0d8e6700d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aquí calculo la desviacion estandar de akgunos atributos para evidenciar por qué las correlaciones son altas analizandolo de forma mas general\n",
    "# y más bajas a nivel de ruta\n",
    "\n",
    "# Sin coordenadas\n",
    "time_by_location_hour_day.select(F.stddev(\"avg_speed_kmh\"), F.stddev(\"avg_prcp\")).show()\n",
    "\n",
    "# Con coordenadas\n",
    "time_by_location_hour.select(F.stddev(\"avg_speed_kmh\"), F.stddev(\"avg_prcp\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0948af9b-a6ea-4d6d-a0d3-01eac696e7c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "time_by_location_hour_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1df10dd6-5676-464e-ad21-572f63cf2cd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convierto la columna 'day_of_week' a tipo entero\n",
    "time_by_location_hour_day_pd['day_of_week'] = time_by_location_hour_day_pd['day_of_week'].astype(int)\n",
    "\n",
    "# Filtro los datos para días laborables y fines de semana (teniendo en cuenta desde el viernes al domingo, no incluido)\n",
    "workdays = time_by_location_hour_day_pd[time_by_location_hour_day_pd['day_of_week'] <= 6]\n",
    "weekends = time_by_location_hour_day_pd[time_by_location_hour_day_pd['day_of_week'] >= 7]\n",
    "\n",
    "# Calculo las matrices de correlación para cada subconjunto\n",
    "corr_workdays = workdays[[\"avg_trip_time_minutes\", \"avg_temp\", \"avg_rhum\", \"avg_speed_kmh\", \"avg_prcp\", \n",
    "                          \"avg_events\", \"avg_wspd\",\"demand_count\", \"avg_distance\"]].corr()\n",
    "\n",
    "corr_weekends = weekends[[\"avg_trip_time_minutes\", \"avg_temp\", \"avg_rhum\", \"avg_speed_kmh\", \"avg_prcp\", \n",
    "                          \"avg_events\", \"avg_wspd\",\"demand_count\", \"avg_distance\"]].corr()\n",
    "\n",
    "# Creo los subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Creo el mapa de calor para los días laborables\n",
    "sns.heatmap(corr_workdays, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, square=True, fmt=\".2f\",\n",
    "            cbar_kws={\"shrink\": .8}, annot_kws={\"size\": 10}, ax=ax1)\n",
    "ax1.set_title(\"Correlación en Días Laborables\", fontsize=14)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45)\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(), rotation=45)\n",
    "\n",
    "# Creo el mapa de calor para los fines de semana\n",
    "sns.heatmap(corr_weekends, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, square=True, fmt=\".2f\",\n",
    "            cbar_kws={\"shrink\": .8}, annot_kws={\"size\": 10}, ax=ax2)\n",
    "ax2.set_title(\"Correlación en Fines de Semana\", fontsize=14)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45)\n",
    "ax2.set_yticklabels(ax2.get_yticklabels(), rotation=45)\n",
    "\n",
    "# Imprimo el gráfico en pantalla\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5758500f-9f47-4c15-a810-e61a396a3a95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creo una tabla pivote para la demanda\n",
    "demand_pivot = time_by_location_hour_pd.pivot_table(\n",
    "    index='day_of_week', \n",
    "    columns='hour', \n",
    "    values='demand_count', \n",
    "    aggfunc='sum'\n",
    ")\n",
    "\n",
    "# Creo una tabla pivote para los tiempos de viaje\n",
    "trip_time_pivot = time_by_location_hour_pd.pivot_table(\n",
    "    index='day_of_week', \n",
    "    columns='hour', \n",
    "    values='avg_trip_time_minutes', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "# Creo una tabla pivote para la velocidad\n",
    "speed_time_pivot = time_by_location_hour_pd.pivot_table(\n",
    "    index='day_of_week', \n",
    "    columns='hour', \n",
    "    values='avg_speed_kmh', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "# Creo el mapa de calor para la demanda\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(demand_pivot, annot=False, fmt='.0f', cmap=\"YlGnBu\", cbar_kws={'label': 'Demanda'}, linewidths=0.5)\n",
    "plt.title('Mapa de Calor: Demanda vs Hora del Día y Día de la Semana')\n",
    "plt.xlabel('Hora del Día')\n",
    "plt.ylabel('Día de la Semana')\n",
    "plt.show()\n",
    "\n",
    "# Creo el mapa de calor para los tiempos de viaje\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(trip_time_pivot, annot=False, fmt='.0f', cmap=\"coolwarm\", cbar_kws={'label': 'Tiempo de Viaje (minutos)'}, linewidths=0.5)\n",
    "plt.title('Mapa de Calor: Tiempo de Viaje Promedio vs Hora del Día y Día de la Semana')\n",
    "plt.xlabel('Hora del Día')\n",
    "plt.ylabel('Día de la Semana')\n",
    "plt.show()\n",
    "\n",
    "# Creo el mapa de calor para la velocidad\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(speed_time_pivot, annot=False, fmt='.0f', cmap=\"coolwarm\", cbar_kws={'label': 'Velocidad promedio (kmh)'}, linewidths=0.5)\n",
    "plt.title('Mapa de Calor: Velocidad promedio vs Hora del Día y Día de la Semana')\n",
    "plt.xlabel('Hora del Día')\n",
    "plt.ylabel('Día de la Semana')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "923b7a36-b014-4360-af9c-91ac18878dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(uber_weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddcb9dfb-c2b4-48f9-99f8-3b28d83e4182",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uber_weather_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abebb54c-244c-4607-9f00-af36ea406771",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creo lista con los atributos que contienen la cantidad de eventos\n",
    "event_columns = ['Athletic Race / Tour', 'BID Multi-Block', 'Bike the Block', 'Block Party', \n",
    "                 'Clean-Up', 'Farmers Market', 'Grid Request', 'Health Fair', \n",
    "                 'Open Culture', 'Open Street Partner Event', 'Parade', \n",
    "                 'Plaza Event', 'Plaza Partner Event', 'Press Conference', \n",
    "                 'Production Event', 'Religious Event', 'Sidewalk Sale', \n",
    "                 'Single Block Festival', 'Special Event', 'Sport - Adult', \n",
    "                 'Sport - Youth', 'Stationary Demonstration', 'Stickball', \n",
    "                 'Street Event', 'Street Festival', 'Theater Load in and Load Outs']\n",
    "\n",
    "# Lista de las condiciones meteorológicas específicas\n",
    "meteorological_columns = ['coco_1.0','coco_20.0', 'coco_15.0','coco_17.0',\n",
    "                          'coco_9.0','coco_12.0','coco_18.0',\n",
    "                          'coco_5.0', 'coco_4.0', 'coco_7.0',\n",
    "                          'coco_2.0', 'coco_8.0','coco_3.0','coco_16.0','coco_13.0']\n",
    "\n",
    "# Selecciono los atributos de interés\n",
    "columns_of_interest = event_columns + meteorological_columns + ['total_trip_time_minutes_avg', 'speed_kmh_avg']\n",
    "\n",
    "# Realizo la agregación de 'speed_kmh' y 'total_trip_time_minutes' por hora y día\n",
    "agg_df = uber_weather_df.groupBy('hour_of_day', 'day_of_week').agg(\n",
    "    avg('speed_kmh').alias('speed_kmh_avg'),\n",
    "    avg('total_trip_time_minutes').alias('total_trip_time_minutes_avg')\n",
    ")\n",
    "# Incorporo el resto de atributos que necesito\n",
    "agg_df = agg_df.join(\n",
    "    uber_weather_df.select(\n",
    "        'hour_of_day', 'day_of_week','Athletic Race / Tour', 'BID Multi-Block', 'Bike the Block',\n",
    "        'Block Party', 'Clean-Up', 'Farmers Market', 'Grid Request', 'Health Fair',\n",
    "        'Open Culture', 'Open Street Partner Event', 'Parade', 'Plaza Event', \n",
    "        'Plaza Partner Event', 'Press Conference', 'Production Event', 'Religious Event', \n",
    "        'Sidewalk Sale', 'Single Block Festival', 'Special Event', 'Sport - Adult', \n",
    "        'Sport - Youth', 'Stationary Demonstration', 'Stickball', 'Street Event', \n",
    "        'Street Festival', 'Theater Load in and Load Outs', 'nº events', 'Hour_int', \n",
    "        'time', 'temp', 'dwpt', 'rhum', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', \n",
    "        'pres', 'tsun', '`coco_1.0`', '`coco_20.0`', '`coco_15.0`', '`coco_17.0`', \n",
    "        '`coco_0.0`', '`coco_9.0`', '`coco_12.0`', '`coco_18.0`', '`coco_14.0`', \n",
    "        '`coco_19.0`', '`coco_5.0`', '`coco_4.0`', '`coco_7.0`', '`coco_2.0`', \n",
    "        '`coco_8.0`', '`coco_3.0`', '`coco_16.0`', '`coco_13.0`', 'total_trip_time_hours'\n",
    "    ),\n",
    "    on=['hour_of_day', 'day_of_week'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Convierto el dataframe de PySpark a pandas para realizar el cálculo de la correlación\n",
    "df_pandas = agg_df.toPandas()\n",
    "\n",
    "# Filtro columnas que están en columns_of_interest y que existen en el DataFrame\n",
    "columns_of_interest = [col for col in columns_of_interest if col in df_pandas.columns]\n",
    "\n",
    "# Elimino columnas con todos los valores nulos\n",
    "df_pandas = df_pandas.dropna(axis=1, how='all')\n",
    "\n",
    "# Elimino columnas con solo un valor único, pero preservando las columnas de interés\n",
    "df_pandas = df_pandas.loc[:, df_pandas.nunique() > 1]\n",
    "\n",
    "# Verifico que las columnas de interés están presentes después de la limpieza\n",
    "columns_of_interest = [col for col in columns_of_interest if col in df_pandas.columns]\n",
    "\n",
    "# Esto me avisa de si alguna columna de interés ha sido eliminada\n",
    "if len(columns_of_interest) < len(event_columns + meteorological_columns + ['total_trip_time_minutes_avg', 'speed_kmh_avg']):\n",
    "    missing_columns = set(event_columns + meteorological_columns + ['total_trip_time_minutes_avg', 'speed_kmh_avg']) - set(columns_of_interest)\n",
    "    print(f\"Advertencia: Algunas columnas de interés han sido eliminadas: {missing_columns}\")\n",
    "\n",
    "# Calculo la matriz de correlación\n",
    "correlation_matrix = df_pandas[columns_of_interest].corr()\n",
    "\n",
    "# Filtro la matriz de correlación para mostrar solo las columnas de 'total_trip_time_minutes' y 'speed_kmh' con el resto\n",
    "correlation_matrix_filtered = correlation_matrix[['total_trip_time_minutes_avg', 'speed_kmh_avg']]\n",
    "\n",
    "# Imprimo en àntalla la matriz de correlación con un mapa de calor\n",
    "plt.figure(figsize=(10, 8))  \n",
    "sns.heatmap(correlation_matrix_filtered, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, center=0, cbar_kws={'shrink': 0.75})\n",
    "plt.title('Correlación entre `total_trip_time_minutes` y `speed_kmh` con el resto de las variables', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aae0cb04-f92c-4330-b46f-4ad3bfa16b87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "correlation_matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e7cf516-77ac-4fe2-971b-0a2a674ca9d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filtro las columnas que tienen alta correlación con 'speed_kmh' y 'total_trip_time_minutes'\n",
    "correlation_with_speed = correlation_matrix['speed_kmh_avg'].sort_values(ascending=False)\n",
    "correlation_with_trip_time = correlation_matrix['total_trip_time_minutes_avg'].sort_values(ascending=False)\n",
    "correlation_with_trip_time.dropna(inplace=True)\n",
    "correlation_with_speed.dropna(inplace=True)\n",
    "# Imprimo los atributos más correlacionados\n",
    "print(\"Atributos más correlacionados positivamente con 'speed_kmh':\")\n",
    "print(correlation_with_speed.head(10))  # Esto muestra los 10 atributos más correlacionados\n",
    "print(\"Atributos más correlacionados negativamente con 'speed_kmh':\")\n",
    "print(correlation_with_speed.tail(10)) \n",
    "print(\"\\nAtributos más correlacionados con 'total_trip_time_minutes':\")\n",
    "print(correlation_with_trip_time.head(10))\n",
    "print(\"Atributos más correlacionados negativamente con 'total_trip_time_minutes':\")\n",
    "print(correlation_with_trip_time.tail(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d30a6d79-187d-45fb-a2e6-232db4d02ef6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creo lista con los atributos que contienen la cantidad de eventos\n",
    "event_columns = ['Athletic Race / Tour', 'BID Multi-Block', 'Bike the Block', 'Block Party', \n",
    "                 'Clean-Up', 'Farmers Market', 'Grid Request', 'Health Fair', \n",
    "                 'Open Culture', 'Open Street Partner Event', 'Parade', \n",
    "                 'Plaza Event', 'Plaza Partner Event', 'Press Conference', \n",
    "                 'Production Event', 'Religious Event', 'Sidewalk Sale', 'Single Block Festival', \n",
    "                 'Special Event', 'Sport - Adult', 'Sport - Youth', 'Stationary Demonstration', \n",
    "                 'Stickball', 'Street Event', 'Street Festival', 'Theater Load in and Load Outs']\n",
    "\n",
    "# Lista de las condiciones meteorológicas específicas\n",
    "meteorological_columns = ['coco_1.0','coco_20.0', 'coco_15.0','coco_17.0',\n",
    "                          'coco_9.0','coco_12.0','coco_18.0','coco_5.0', \n",
    "                          'coco_4.0', 'coco_7.0','coco_2.0','coco_8.0','coco_3.0','coco_16.0','coco_13.0']\n",
    "\n",
    "# Selecciono las columnas de interés\n",
    "columns_of_interest = event_columns + meteorological_columns + ['total_trip_time_minutes', 'speed_kmh', 'trip_kilometers']\n",
    "\n",
    "# Convierto el dataframe de PySpark a pandas para realizar el cálculo de la correlación\n",
    "df_pandas = uber_weather_df.toPandas()\n",
    "\n",
    "# Filtro columnas que están en columns_of_interest y que existen en el DataFrame\n",
    "columns_of_interest = [col for col in columns_of_interest if col in df_pandas.columns]\n",
    "\n",
    "# Elimino columnas con todos los valores nulos\n",
    "df_pandas = df_pandas.dropna(axis=1, how='all')\n",
    "\n",
    "# Elimino columnas con solo un valor único, pero preservando las columnas de interés\n",
    "df_pandas = df_pandas.loc[:, df_pandas.nunique() > 1]\n",
    "\n",
    "# Verifico que las columnas de interés están presentes después de la limpieza\n",
    "columns_of_interest = [col for col in columns_of_interest if col in df_pandas.columns]\n",
    "\n",
    "# Esto me avisa de si alguna columna de interés ha sido eliminada\n",
    "if len(columns_of_interest) < len(event_columns + meteorological_columns + ['total_trip_time_minutes', 'speed_kmh', 'trip_kilometers']):\n",
    "    missing_columns = set(event_columns + meteorological_columns + ['total_trip_time_minutes', 'speed_kmh', 'trip_kilometers']) - set(columns_of_interest)\n",
    "    print(f\"Advertencia: Algunas columnas de interés han sido eliminadas: {missing_columns}\")\n",
    "\n",
    "# Divido los trayectos en cortos y largos según los kilómetros del trayecto\n",
    "median_trip_km = df_pandas['trip_kilometers'].median()\n",
    "\n",
    "# Filtro los trayectos cortos (menos que la mediana de kilómetros)\n",
    "df_short_trips = df_pandas[df_pandas['trip_kilometers'] < median_trip_km]\n",
    "\n",
    "# Filtro los trayectos largos (mayores o iguales a la mediana de kilómetros)\n",
    "df_long_trips = df_pandas[df_pandas['trip_kilometers'] >= median_trip_km]\n",
    "\n",
    "# Calculo la matriz de correlación para trayectos cortos\n",
    "correlation_matrix_short = df_short_trips[columns_of_interest].corr()\n",
    "\n",
    "# Filtro la matriz de correlación para mostrar solo las columnas de 'total_trip_time_minutes' y 'speed_kmh'\n",
    "correlation_matrix_short_filtered = correlation_matrix_short[['total_trip_time_minutes', 'speed_kmh']]\n",
    "\n",
    "# Calculo la matriz de correlación para trayectos largos\n",
    "correlation_matrix_long = df_long_trips[columns_of_interest].corr()\n",
    "\n",
    "# Filtro la matriz de correlación para mostrar solo las columnas de 'total_trip_time_minutes' y 'speed_kmh'\n",
    "correlation_matrix_long_filtered = correlation_matrix_long[['total_trip_time_minutes', 'speed_kmh']]\n",
    "\n",
    "# Imprimo la matriz de correlación para trayectos cortos\n",
    "plt.figure(figsize=(10, 8))  # Tamaño de la figura adecuado\n",
    "sns.heatmap(correlation_matrix_short_filtered, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, center=0, cbar_kws={'shrink': 0.75})\n",
    "plt.title('Correlación entre `total_trip_time_minutes` y `speed_kmh` (Trayectos Cortos)', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Imprimo la matriz de correlación para trayectos largos\n",
    "plt.figure(figsize=(10, 8))  # Tamaño de la figura adecuado\n",
    "sns.heatmap(correlation_matrix_long_filtered, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, center=0, cbar_kws={'shrink': 0.75})\n",
    "plt.title('Correlación entre `total_trip_time_minutes` y `speed_kmh` (Trayectos Largos)', fontsize=16)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "005e5c3f-31ad-4dee-afa2-57ebec6f0567",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pandas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a48d2355-b1e3-48a9-b675-b380175de678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creo lista con los atributos que contienen la cantidad de eventos\n",
    "event_columns = ['Athletic Race / Tour', 'BID Multi-Block', 'Bike the Block', 'Block Party', \n",
    "                 'Clean-Up', 'Farmers Market', 'Grid Request', 'Health Fair', \n",
    "                 'Open Culture', 'Open Street Partner Event', 'Parade', \n",
    "                 'Plaza Event', 'Plaza Partner Event', 'Press Conference', \n",
    "                 'Production Event', 'Religious Event', 'Sidewalk Sale', \n",
    "                 'Single Block Festival', 'Special Event', 'Sport - Adult', \n",
    "                 'Sport - Youth', 'Stationary Demonstration', 'Stickball', \n",
    "                 'Street Event', 'Street Festival', 'Theater Load in and Load Outs']\n",
    "\n",
    "# Lista de las condiciones meteorológicas específicas\n",
    "meteorological_columns = ['coco_1.0','coco_20.0', 'coco_15.0','coco_17.0',\n",
    "                          'coco_9.0','coco_12.0','coco_18.0',\n",
    "                          'coco_5.0', 'coco_4.0', 'coco_7.0',\n",
    "                          'coco_2.0', 'coco_8.0','coco_3.0','coco_16.0','coco_13.0']\n",
    "\n",
    "# Selecciono las columnas de interés\n",
    "columns_of_interest = event_columns + meteorological_columns + ['total_trip_time_minutes_avg', 'speed_kmh_avg']\n",
    "\n",
    "# Realizo la agregación de 'speed_kmh' y 'total_trip_time_minutes' por hora y día\n",
    "agg_df = uber_weather_df.groupBy('hour_of_day', 'day_of_week').agg(\n",
    "    avg('speed_kmh').alias('speed_kmh_avg'),\n",
    "    avg('total_trip_time_minutes').alias('total_trip_time_minutes_avg')\n",
    ")\n",
    "\n",
    "# Incorporo las demás columnas que necesito\n",
    "agg_df = agg_df.join(\n",
    "    uber_weather_df.select(\n",
    "        'hour_of_day', 'day_of_week','Athletic Race / Tour', 'BID Multi-Block', 'Bike the Block',\n",
    "        'Block Party', 'Clean-Up', 'Farmers Market', 'Grid Request', 'Health Fair',\n",
    "        'Open Culture', 'Open Street Partner Event', 'Parade', 'Plaza Event', \n",
    "        'Plaza Partner Event', 'Press Conference', 'Production Event', 'Religious Event', \n",
    "        'Sidewalk Sale', 'Single Block Festival', 'Special Event', 'Sport - Adult', \n",
    "        'Sport - Youth', 'Stationary Demonstration', 'Stickball', 'Street Event', \n",
    "        'Street Festival', 'Theater Load in and Load Outs', 'nº events', 'Hour_int', \n",
    "        'time', 'temp', 'dwpt', 'rhum', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', \n",
    "        'pres', 'tsun', '`coco_1.0`', '`coco_20.0`', '`coco_15.0`', '`coco_17.0`', \n",
    "        '`coco_0.0`', '`coco_9.0`', '`coco_12.0`', '`coco_18.0`', '`coco_14.0`', \n",
    "        '`coco_19.0`', '`coco_5.0`', '`coco_4.0`', '`coco_7.0`', '`coco_2.0`', \n",
    "        '`coco_8.0`', '`coco_3.0`', '`coco_16.0`', '`coco_13.0`', 'total_trip_time_hours'\n",
    "    ),\n",
    "    on=['hour_of_day', 'day_of_week'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Convierto el dataframe de PySpark a pandas para realizar el cálculo de la correlación\n",
    "df_pandas = agg_df.toPandas()\n",
    "\n",
    "# Filtro columnas que están en columns_of_interest y que existen en el DataFrame\n",
    "columns_of_interest = [col for col in columns_of_interest if col in df_pandas.columns]\n",
    "\n",
    "# Elimino columnas con todos los valores nulos\n",
    "df_pandas = df_pandas.dropna(axis=1, how='all')\n",
    "\n",
    "# Elimino columnas con solo un valor único, pero preservando las columnas de interés\n",
    "df_pandas = df_pandas.loc[:, df_pandas.nunique() > 1]\n",
    "\n",
    "# Verifico que las columnas de interés están presentes después de la limpieza\n",
    "columns_of_interest = [col for col in columns_of_interest if col in df_pandas.columns]\n",
    "\n",
    "# Esto me avisa de si alguna columna de interés ha sido eliminada\n",
    "if len(columns_of_interest) < len(event_columns + meteorological_columns + ['total_trip_time_minutes_avg', 'speed_kmh_avg']):\n",
    "    missing_columns = set(event_columns + meteorological_columns + ['total_trip_time_minutes_avg', 'speed_kmh_avg']) - set(columns_of_interest)\n",
    "    print(f\"Advertencia: Algunas columnas de interés han sido eliminadas: {missing_columns}\")\n",
    "\n",
    "# Defino los momentos del día según la columna 'hour_of_day'\n",
    "def get_moment_of_day(hour):\n",
    "    if 0 <= hour <= 5:\n",
    "        return 'Madrugada'\n",
    "    elif 6 <= hour <= 11:\n",
    "        return 'Mañana'\n",
    "    elif 12 <= hour <= 17:\n",
    "        return 'Tarde'\n",
    "    elif 18 <= hour <= 23:\n",
    "        return 'Noche'\n",
    "    else:\n",
    "        return 'Desconocido'  # En caso de valores fuera de rango\n",
    "\n",
    "# Creo la columna 'moment_of_day' en el df\n",
    "df_pandas['moment_of_day'] = df_pandas['hour_of_day'].apply(get_moment_of_day)\n",
    "\n",
    "# Creo listas de momentos del día\n",
    "moments = ['Madrugada', 'Mañana', 'Tarde', 'Noche']\n",
    "\n",
    "# Creo la figura para subplots 2x2\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))  # Tamaño adecuado para los subplots\n",
    "\n",
    "# Ajusto el espacio entre subplots (mejora la visualización en la interfaz)\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Creo los subplots para visualizar correlaciones por momento del día\n",
    "for i, moment in enumerate(moments):\n",
    "    ax = axes[i // 2, i % 2]  # Determina la posición del subplot (2x2)\n",
    "\n",
    "    # Filtro por momento del día\n",
    "    df_filtered = df_pandas[df_pandas['moment_of_day'] == moment]\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        print(f\"No hay datos para el momento '{moment}'.\")\n",
    "        continue\n",
    "\n",
    "    # Calculo la matriz de correlación solo con las columnas de interés existentes\n",
    "    correlation_matrix = df_filtered[columns_of_interest].corr()\n",
    "    correlation_filtered = correlation_matrix[['total_trip_time_minutes_avg', 'speed_kmh_avg']]\n",
    "\n",
    "    # Visualizo la matriz de correlación con un heatmap\n",
    "    sns.heatmap(correlation_filtered, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, center=0, cbar_kws={'shrink': 0.75}, ax=ax)\n",
    "    ax.set_title(f'Correlación en {moment}', fontsize=14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce68f398-2dc7-48b0-9ad3-0c91d4628973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "time_by_location_hour_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "252e5194-8303-4744-8526-9eeef708ee03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwuwRB8H4Q7z",
    "outputId": "c5455d85-1374-4bee-e011-cd9512be76f0"
   },
   "outputs": [],
   "source": [
    "# Encuentro las rutas más populares por demanda\n",
    "top_routes = (\n",
    "    time_by_location_hour_pd.groupby(\n",
    "        [\"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\", \"dropoff_longitude\"]\n",
    "    )[\"demand_count\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .sort_values(\"demand_count\", ascending=False)\n",
    "    .head(10)  # Top 10 rutas\n",
    ")\n",
    "\n",
    "print(\"Top 10 rutas con mayor demanda:\")\n",
    "display(top_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "666572a0-2116-444b-8fb2-89711cc06932",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRsk-GeVAnVg",
    "outputId": "3917062d-2678-49eb-a484-3b3d85f830d0"
   },
   "outputs": [],
   "source": [
    "print(\"Número de rutas en el top_routes:\", len(top_routes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a8eb679-fe14-4fed-8f49-0fd564af06e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "kBL_i2cL_zkR"
   },
   "outputs": [],
   "source": [
    "# Creo un mapa centrado en la ubicación promedio de las rutas más populares\n",
    "center_lat = top_routes[\"pickup_latitude\"].mean()\n",
    "center_lon = top_routes[\"pickup_longitude\"].mean()\n",
    "map_routes = folium.Map(location=[center_lat, center_lon], zoom_start=12)\n",
    "\n",
    "# Creo un clúster para los marcadores\n",
    "marker_cluster = MarkerCluster().add_to(map_routes)\n",
    "\n",
    "# Lista de colores para las rutas\n",
    "colors = ['blue', 'green', 'orange', 'red', 'purple', 'darkred', 'lightred', 'beige', 'darkblue', 'cadetblue']\n",
    "\n",
    "# Añado solo las 10 rutas más populares al mapa\n",
    "for i, (_, row) in enumerate(top_routes.iterrows()):\n",
    "    origin = [row[\"pickup_latitude\"], row[\"pickup_longitude\"]]\n",
    "    destination = [row[\"dropoff_latitude\"], row[\"dropoff_longitude\"]]\n",
    "\n",
    "    # Añado marcadores para el origen y destino\n",
    "    folium.Marker(\n",
    "        origin,\n",
    "        icon=folium.Icon(color='green', icon='arrow-up', prefix='fa'),\n",
    "        tooltip=\"Origen\"\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "    folium.Marker(\n",
    "        destination,\n",
    "        icon=folium.Icon(color='red', icon='arrow-down', prefix='fa'),\n",
    "        tooltip=\"Destino\"\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "    # Añado línea entre el origen y el destino para visualizar la ruta\n",
    "    folium.PolyLine(\n",
    "        [origin, destination],\n",
    "        color=colors[i % len(colors)],  # Usar un color de la lista\n",
    "        weight=5,  # Grosor de la línea\n",
    "        opacity=0.7,  # Opacidad de la línea\n",
    "        tooltip=f\"Demand Count: {row['demand_count']}\"\n",
    "    ).add_to(map_routes)\n",
    "\n",
    "# Imprimo el mapa en pantalla\n",
    "display(map_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffb9f00b-f5ab-466d-af07-7b589b20303c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mySoQbJA4h9P",
    "outputId": "46ac01eb-e004-42d6-c085-fd876a46e57d"
   },
   "outputs": [],
   "source": [
    "# Rutas con alta demanda (top 10%)\n",
    "high_demand_routes = time_by_location_hour_pd[\n",
    "    time_by_location_hour_pd[\"demand_count\"] >= time_by_location_hour_pd[\"demand_count\"].quantile(0.9)\n",
    "]\n",
    "\n",
    "# Rutas con baja demanda (bottom 10%)\n",
    "low_demand_routes = time_by_location_hour_pd[\n",
    "    time_by_location_hour_pd[\"demand_count\"] <= time_by_location_hour_pd[\"demand_count\"].quantile(0.1)\n",
    "]\n",
    "\n",
    "print(\"Rutas con alta demanda (top 10%):\")\n",
    "display(high_demand_routes)\n",
    "\n",
    "print(\"Rutas con baja demanda (bottom 10%):\")\n",
    "display(low_demand_routes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6c3ab17-8bb6-4c9c-bd8d-9aa6d97f9185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-yZMt3f4Rqd",
    "outputId": "9a8d5266-aedb-440a-8c07-36e869076a59"
   },
   "outputs": [],
   "source": [
    "# Calculo la distancia por medio de Función Haversine\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radio de la Tierra en km\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(delta_phi / 2) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c  # Distancia en km\n",
    "\n",
    "# Calculo la distancia entre pares de ubicaciones\n",
    "time_by_location_hour_pd[\"avg_distance\"] = time_by_location_hour_pd.apply(\n",
    "    lambda row: haversine(\n",
    "        row[\"pickup_latitude\"], row[\"pickup_longitude\"],\n",
    "        row[\"dropoff_latitude\"], row[\"dropoff_longitude\"]\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Agrupo los datos en función de la distancia y analizo la correlación con las variables meteorológicas\n",
    "short_trips = time_by_location_hour_pd[time_by_location_hour_pd[\"avg_distance\"] <= 5]\n",
    "long_trips = time_by_location_hour_pd[time_by_location_hour_pd[\"avg_distance\"] > 5]\n",
    "\n",
    "print(\"Correlación para trayectos cortos (<=5 km):\")\n",
    "print(short_trips[[\"avg_trip_time_minutes\", \"avg_temp\", \"avg_rhum\", \"avg_speed_kmh\", \"avg_prcp\", \"avg_events\", \"demand_count\"]].corr())\n",
    "\n",
    "print(\"Correlación para trayectos largos (>5 km):\")\n",
    "print(long_trips[[\"avg_trip_time_minutes\", \"avg_temp\", \"avg_rhum\", \"avg_speed_kmh\", \"avg_prcp\", \"avg_events\", \"demand_count\"]].corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99e84342-443f-459a-8baa-2d2f8e646dbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IxA42y7fN49K"
   },
   "outputs": [],
   "source": [
    "demand_by_location_date = uber_weather_df.groupBy(\n",
    "    F.col(\"pickup_latitude\").alias(\"latitude\"),\n",
    "    F.col(\"pickup_longitude\").alias(\"longitude\"),\n",
    "    F.to_date(\"request_datetime\").alias(\"date\")\n",
    ").count().alias(\"demand_count\")\n",
    "\n",
    "# Convierto a Pandas para pasar a Folium\n",
    "demand_by_location_date_pd = demand_by_location_date.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2567e27a-012a-4f6a-b717-71f04de5966c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ffjs1iHopVBM"
   },
   "outputs": [],
   "source": [
    "demand_by_location_date_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d6db21-d448-47ff-9983-21b2d577b2fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z6l0M957qqzS",
    "outputId": "f7d48842-aa45-4b29-ff68-6b7f84cb38cd"
   },
   "outputs": [],
   "source": [
    "# Agrupo por las columnas deseadas y calcular la cantidad total de solicitudes y el retraso promedio\n",
    "grouped_data = uber_weather_df.groupBy(\n",
    "    'pickup_latitude',\n",
    "    'pickup_longitude',\n",
    "    'dropoff_latitude',\n",
    "    'dropoff_longitude',\n",
    "    'hour_of_day',\n",
    "    'day_of_week'\n",
    ").agg(\n",
    "    F.count('pickup_location_id').alias('total_requests'),  # Total de solicitudes\n",
    "    F.avg('delay_minutes').alias('avg_delay')  # Retraso promedio\n",
    ")\n",
    "\n",
    "# Imprimo los resultados\n",
    "grouped_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d94c14-a5b9-45e5-87d5-863b6b1b5e71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "id": "vrzLBVN6qvQh",
    "outputId": "56948739-5170-4b78-a0b7-e6f23dc8ae12"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creo un mapa centrado en Nueva York\n",
    "map_ny = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "# Filtro y agrupo los datos en Spark para minimizar tamaño\n",
    "grouped_data_filtered = (\n",
    "    grouped_data\n",
    "    .filter(\n",
    "        (grouped_data.pickup_latitude.isNotNull()) &\n",
    "        (grouped_data.pickup_longitude.isNotNull()) &\n",
    "        (grouped_data.total_requests.isNotNull())\n",
    "    )\n",
    "    .groupBy(\"pickup_latitude\", \"pickup_longitude\")\n",
    "    .sum(\"total_requests\")\n",
    "    .withColumnRenamed(\"sum(total_requests)\", \"total_requests\")\n",
    ")\n",
    "\n",
    "# Convierto a pandas solo las columnas necesarias para el mapa\n",
    "grouped_data_pd = grouped_data_filtered.select(\"pickup_latitude\", \"pickup_longitude\", \"total_requests\").toPandas()\n",
    "grouped_data_pd = grouped_data_pd.dropna()\n",
    "# Creo los datos para el mapa de calor\n",
    "heat_data = [\n",
    "    [row['pickup_latitude'], row['pickup_longitude'], row['total_requests']] \n",
    "    for index, row in grouped_data_pd.iterrows()\n",
    "]\n",
    "HeatMap(heat_data, radius=15).add_to(map_ny)\n",
    "\n",
    "# Visualizo el mapa en pantalla en Jupyter\n",
    "display(map_ny) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e49b280-d606-43da-8b74-cf442d2ffe0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "id": "vz1VUophq3G-",
    "outputId": "3d30ca30-09ac-4d36-b556-5db8655c59ab"
   },
   "outputs": [],
   "source": [
    "# Creo un mapa centrado en Nueva York para los retrasos\n",
    "map_delays = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "# Filtro y agrupo los datos en Spark para reducir el tamaño\n",
    "grouped_data_filtered = (\n",
    "    grouped_data\n",
    "    .filter(\n",
    "        (grouped_data.pickup_latitude.isNotNull()) &\n",
    "        (grouped_data.pickup_longitude.isNotNull()) &\n",
    "        (grouped_data.avg_delay.isNotNull())\n",
    "    )\n",
    "    .groupBy(\"pickup_latitude\", \"pickup_longitude\")\n",
    "    .avg(\"avg_delay\")\n",
    "    .withColumnRenamed(\"avg(avg_delay)\", \"avg_delay\")\n",
    ")\n",
    "\n",
    "# Convierto a pandas solo las columnas necesarias para el mapa\n",
    "grouped_data_pd = grouped_data_filtered.select(\"pickup_latitude\", \"pickup_longitude\", \"avg_delay\").toPandas()\n",
    "\n",
    "grouped_data_pd= grouped_data_pd.dropna()\n",
    "# Creo los datos para el mapa de calor de retrasos\n",
    "delay_data = [\n",
    "    [row['pickup_latitude'], row['pickup_longitude'], row['avg_delay']]\n",
    "    for index, row in grouped_data_pd.iterrows()\n",
    "]\n",
    "HeatMap(delay_data, radius=15).add_to(map_delays)\n",
    "\n",
    "# Imprimo el mapa en pantalla\n",
    "display(map_delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47afea00-4cd6-423d-ae7b-710fd166fd03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "KMbr7TqNXnAI"
   },
   "outputs": [],
   "source": [
    "# Selecciono las características relevantes para el clustering\n",
    "features = time_by_location_hour_pd[[\n",
    "    \"demand_count\", \"avg_prcp\",\n",
    "    \"avg_speed_kmh\", \"avg_trip_time_minutes\", \"avg_events\", \"avg_distance\"\n",
    "]]\n",
    "\n",
    "# Elimino las filas con valores NaN en las características relevantes\n",
    "features_clean = features.dropna()\n",
    "\n",
    "# Normalizo las características\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features_clean)\n",
    "\n",
    "# Aplico KMeans clustering\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "clusters = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# Añado la columna con el cluster pertinente\n",
    "features_clean['cluster'] = clusters\n",
    "\n",
    "# Muestra solo la media de las características para cada clúster\n",
    "cluster_means = features_clean.groupby('cluster').mean()\n",
    "\n",
    "# Muestra el resumen de las medias por clúster\n",
    "print(\"Medias de las características por clúster:\")\n",
    "display(cluster_means)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "new_york_urban_transportation_analysis",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
